Homework2
================
Yunjia Liu
2024-09-30

## Problem1

### 1. Process the data

Input data and do using clean_names() to clean the data. Using select()
to choose the required columns. Specially when treating all the
route1~route11, I use the starts_with() function to simplify the
process. And then I use mutate to convert ‘entry’ from character to
logical variable.

``` r
nyctransit_df = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") |>
  janitor::clean_names() |>
  select(line, station_name, station_latitude, station_longitude, starts_with("route"), entry, vending, entrance_type, ada) |>
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
head(nyctransit_df)
```

    ## # A tibble: 6 × 19
    ##   line     station_name station_latitude station_longitude route1 route2 route3
    ##   <chr>    <chr>                   <dbl>             <dbl> <chr>  <chr>  <chr> 
    ## 1 4 Avenue 25th St                  40.7             -74.0 R      <NA>   <NA>  
    ## 2 4 Avenue 25th St                  40.7             -74.0 R      <NA>   <NA>  
    ## 3 4 Avenue 36th St                  40.7             -74.0 N      R      <NA>  
    ## 4 4 Avenue 36th St                  40.7             -74.0 N      R      <NA>  
    ## 5 4 Avenue 36th St                  40.7             -74.0 N      R      <NA>  
    ## 6 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ## # ℹ 12 more variables: route4 <chr>, route5 <chr>, route6 <chr>, route7 <chr>,
    ## #   route8 <dbl>, route9 <dbl>, route10 <dbl>, route11 <dbl>, entry <lgl>,
    ## #   vending <chr>, entrance_type <chr>, ada <lgl>

``` r
num_rows = nrow(nyctransit_df)
num_cols = ncol(nyctransit_df)
cat("The dataset has", num_rows, "rows and", num_cols, "columns.\n")
```

    ## The dataset has 1868 rows and 19 columns.

### 2. Summary:

2.1. Variables in the data: - line: The subway line the station belongs
to. - station_name: Name of the station. - station_latitude /
station_longitude: Geographic coordinates of the station. -
routes1~routes11: Subway routes served by the station. - entry: whether
the entrance allows entry. - vending: Whether the entrance has a vending
machine. - entrance_type: Type of entrance - ada: whether the entrance
is ADA compliant.

2.2. Cleaning steps: After using clean_names() to rename the variables,
I retained the relevant columns, converted the entry column to a logical
variable, and inspected the data for consistency. The dataset contains
1868 rows and 19 columns. As far as I am concerned, the data is
relatively neat because each row corresponds to an entry and each
variable has a different value.

### 3. Quesiton

3.1 Number of distinct stations.

``` r
distinct_stations = nyctransit_df |>
  distinct(line, station_name)

num_distinct_stations <- nrow(distinct_stations)
cat("Number of distinct stations: ", num_distinct_stations, "\n")
```

    ## Number of distinct stations:  465

3.2 Number of stations that are ADA compliant.

``` r
ada_compliant = nyctransit_df |>
  filter(ada == "TRUE") |>
  distinct(line, station_name)

num_ada_compliant = nrow(ada_compliant)
cat("Number of ADA compliant stations: ", num_ada_compliant, "\n")
```

    ## Number of ADA compliant stations:  84

3.3 Proportion of entrances without vending allow entrance.

``` r
no_vending_entry = nyctransit_df |>
  filter(vending == "NO") |>
  summarise(proportion_entry = mean(entry))

cat("Proportion of entrances without vending allow entrance: ", no_vending_entry$proportion_entry, "\n")
```

    ## Proportion of entrances without vending allow entrance:  0.3770492

3.4 Question4

Reformat the dataset. Using mutate(across(…)) to convert all route
columns to characters so that all route1~route11 columns are characters.
Using pivot_longer to combine all route1~route11 columns into a single
“route_name” column and make the original column as “route_number”.(I am
bit confuse about the description)

``` r
# Use pivot_longer to combine all route1~route11 columns into a single "route" column

transit_reformat = nyctransit_df |>
  mutate(across(starts_with("route"), as.character)) |>
   pivot_longer(route1:route11, names_to = "route_number", values_to = "route_name", values_drop_na = TRUE)
head(transit_reformat)
```

    ## # A tibble: 6 × 10
    ##   line     station_name station_latitude station_longitude entry vending
    ##   <chr>    <chr>                   <dbl>             <dbl> <lgl> <chr>  
    ## 1 4 Avenue 25th St                  40.7             -74.0 TRUE  YES    
    ## 2 4 Avenue 25th St                  40.7             -74.0 TRUE  YES    
    ## 3 4 Avenue 36th St                  40.7             -74.0 TRUE  YES    
    ## 4 4 Avenue 36th St                  40.7             -74.0 TRUE  YES    
    ## 5 4 Avenue 36th St                  40.7             -74.0 TRUE  YES    
    ## 6 4 Avenue 36th St                  40.7             -74.0 TRUE  YES    
    ## # ℹ 4 more variables: entrance_type <chr>, ada <lgl>, route_number <chr>,
    ## #   route_name <chr>

Filter the dataset to find stations that serve the A train and count the
number of distinct stations serving the A train

``` r
a_train_stations = transit_reformat |>
  filter(route_name == "A") |>
  distinct(line, station_name)

num_a_train_stations = nrow(a_train_stations)
cat("Number of distinct stations serving the A train: ", num_a_train_stations, "\n")
```

    ## Number of distinct stations serving the A train:  60

Find the number of A train stations that are ADA compliant and count the
number of ADA compliant stations serving the A train.

``` r
ada_compliant_a_train = transit_reformat |>
  filter(route_name == "A") |>
  filter(ada == "TRUE") |>
  distinct(line, station_name)

num_ada_compliant_a_train = nrow(ada_compliant_a_train)
cat("Number of ADA compliant stations serving the A train: ", num_ada_compliant_a_train, "\n")
```

    ## Number of ADA compliant stations serving the A train:  17

## Problem2

### 1. Process the data

1.1 Input the data in ‘Mr. Trash Wheel’ Sheet from
‘202409_Trash_Wheel_Collection_Data.xlsx’ and point to the specific
sheet ‘Mr. Trash Wheel’. I am skipping the first row because the it
contains a picture and logo. Also, I use only col form A to N because
the column O and column P are completely emtpy column. Then, use
janitor::clean_names() to rename the variables and NA of ‘dumpster’
variable is dropped. According the requirement, I rounded the
‘sports_balls’ variable and convert it to integar and change the type of
‘year’ variables from character to integer. Finally, I use mutate()
function to create a new column in order to record the sourcing
(‘Mr. Trash Wheel’) of the dataset.

``` r
mr_trash_wheel =
  read_excel("./data/202409_Trash_Wheel_Collection_Data.xlsx", sheet = "Mr. Trash Wheel", range = cell_cols("A:N"), skip = 1, na = c("NA", ".", "")) |>
  janitor::clean_names() |>
  drop_na(dumpster)|>
  mutate(
    sports_balls = as.integer(round(sports_balls, 0)), 
    trash_wheel = "Mr. Trash Wheel",
    year = as.integer(year))
```

1.2 Read and clean Professor Trash Wheel sheet & Gwynnda’s data sheet.
They are both skipping the first row because the sheet starts with a
logo in the first row. Combine all three separate datasets together.

``` r
prof_trash_wheel = read_excel("./data/202409_Trash_Wheel_Collection_Data.xlsx", 
                                sheet = "Professor Trash Wheel", 
                                skip = 1,  # Adjust based on where data starts
                                col_names = TRUE,
                                na = c("NA", ".", "")) |>
  janitor::clean_names() |>
  drop_na(dumpster)|>
  mutate(
    year = as.integer(year),
    trash_wheel = "Professor Trash Wheel"
  )

gwynnda_trash_wheel = read_excel("./data/202409_Trash_Wheel_Collection_Data.xlsx", 
                                   sheet = "Gwynnda Trash Wheel", 
                                   skip = 1,
                                   col_names = TRUE,
                                  na = c("NA", ".", "")) |>
  janitor::clean_names() |>
  drop_na(dumpster)|>
  mutate(
    year = as.integer(year),
    trash_wheel = "Gwynnda Trash Wheel"
  )

# Combine datasets into one tidy dataset
combined_trash_data <- bind_rows(mr_trash_wheel, prof_trash_wheel, gwynnda_trash_wheel)
```

### 2. Answer to the question:

2.1.total weight of trash collected by Professor Trash Wheel

``` r
total_weight_prof = combined_trash_data |>
  filter(trash_wheel == "Professor Trash Wheel") |>
  summarise(total_weight = sum(weight_tons, na.rm = TRUE))
```

2.2. total number of cigarette butts collected by Gwynnda in June 2022:

``` r
total_cig_butts_gwynnda = combined_trash_data |>
  filter(trash_wheel == "Gwynnda Trash Wheel" & month(date) == 6 & year == 2022) |>
  summarise(total_cig_butts = sum(`cigarette_butts`, na.rm = TRUE))
```

### 3. Summary:

``` r
n_observations = nrow(combined_trash_data)
total_weight_prof = total_weight_prof$total_weight
total_cig_butts_gwynnda = total_cig_butts_gwynnda$total_cig_butts

cat("The combined dataset includes", n_observations, "observations from three Trash Wheels: Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda. 
Key variables in the dataset include `weight_tons` (the weight of trash collected in tons) and `cigarette_butts`. 
For example, Professor Trash Wheel has collected a total of", total_weight_prof, "tons of trash. 
In June 2022, Gwynnda collected a total of", total_cig_butts_gwynnda, "cigarette butts.")
```

    ## The combined dataset includes 1033 observations from three Trash Wheels: Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda. 
    ## Key variables in the dataset include `weight_tons` (the weight of trash collected in tons) and `cigarette_butts`. 
    ## For example, Professor Trash Wheel has collected a total of 246.74 tons of trash. 
    ## In June 2022, Gwynnda collected a total of 18120 cigarette butts.

## Problem3

3.1 Input three datasets. I split the ‘baker_name’ variable in the
‘bakers.csv’ because it is the full name of the baker, however the rest
two datasets are using the first name of the baker.

``` r
bakers_df = 
  read_csv("./data/gbb_datasets/bakers.csv") |>
  janitor::clean_names() |>
  mutate(
    baker = str_split(baker_name, " ", simplify = T)[,1]
  )

bakes_df = 
  read_csv("./data/gbb_datasets/bakes.csv") |>
  janitor::clean_names()

results_df =  
  read_csv("./data/gbb_datasets/results.csv",skip = 2) |>
  janitor::clean_names() |>
  drop_na(baker)
```

3.2 Using anti_join() to check for completeness and correctness across
datasets

``` r
unmatched_bakes_bakers <- bakes_df%>%
  anti_join(bakers_df, by = c("baker", "series"))
print(unmatched_bakes_bakers)
```

    ## # A tibble: 8 × 5
    ##   series episode baker    signature_bake                            show_stopper
    ##    <dbl>   <dbl> <chr>    <chr>                                     <chr>       
    ## 1      2       1 "\"Jo\"" Chocolate Orange CupcakesOrange and Card… Chocolate a…
    ## 2      2       2 "\"Jo\"" Caramelised Onion, Gruyere and Thyme Qui… Raspberry a…
    ## 3      2       3 "\"Jo\"" Stromboli flavored with Mozzarella, Ham,… Unknown     
    ## 4      2       4 "\"Jo\"" Lavender Biscuits                         Blueberry M…
    ## 5      2       5 "\"Jo\"" Salmon and Asparagus Pie                  Apple and R…
    ## 6      2       6 "\"Jo\"" Rum and Raisin Baked Cheesecake           Limoncello …
    ## 7      2       7 "\"Jo\"" Raspberry & Strawberry Mousse Cake        Pain Aux Ra…
    ## 8      2       8 "\"Jo\"" Raspberry and Blueberry Mille Feuille     Mini Victor…

``` r
unmatched_results_bakers <- results_df %>%
  anti_join(bakers_df, by = c("baker", "series"))
print(unmatched_results_bakers)
```

    ## # A tibble: 8 × 5
    ##   series episode baker  technical result    
    ##    <dbl>   <dbl> <chr>      <dbl> <chr>     
    ## 1      2       1 Joanne        11 IN        
    ## 2      2       2 Joanne        10 IN        
    ## 3      2       3 Joanne         1 IN        
    ## 4      2       4 Joanne         8 IN        
    ## 5      2       5 Joanne         6 IN        
    ## 6      2       6 Joanne         1 STAR BAKER
    ## 7      2       7 Joanne         3 IN        
    ## 8      2       8 Joanne         1 WINNER

``` r
unmatched_bakes_results <- bakes_df %>%
  anti_join(results_df, by = c("baker", "series", "episode"))
print(unmatched_bakes_results)
```

    ## # A tibble: 8 × 5
    ##   series episode baker    signature_bake                            show_stopper
    ##    <dbl>   <dbl> <chr>    <chr>                                     <chr>       
    ## 1      2       1 "\"Jo\"" Chocolate Orange CupcakesOrange and Card… Chocolate a…
    ## 2      2       2 "\"Jo\"" Caramelised Onion, Gruyere and Thyme Qui… Raspberry a…
    ## 3      2       3 "\"Jo\"" Stromboli flavored with Mozzarella, Ham,… Unknown     
    ## 4      2       4 "\"Jo\"" Lavender Biscuits                         Blueberry M…
    ## 5      2       5 "\"Jo\"" Salmon and Asparagus Pie                  Apple and R…
    ## 6      2       6 "\"Jo\"" Rum and Raisin Baked Cheesecake           Limoncello …
    ## 7      2       7 "\"Jo\"" Raspberry & Strawberry Mousse Cake        Pain Aux Ra…
    ## 8      2       8 "\"Jo\"" Raspberry and Blueberry Mille Feuille     Mini Victor…

3.3 From the results, it is obvious that the ‘' (’baker’ variables) in
bakes.csv and baker.csv is referring to the ‘Joanne’ (‘baker’ variables)
in results.csv. The following code is for this correction, renaming the
‘Joanne’ and ‘"Jo"’to ’Jo’ in the results_df and bakes_df respectively.

``` r
results_df_clean = 
  results_df |>
  mutate(baker = recode(baker, 'Joanne' = 'Jo'))

bakes_df_clean =
  bakes_df |>
  mutate(baker = recode(baker,'\"Jo\"' = 'Jo'))
```

3.4 recheck the completeness and correctness across datasets after
re-cleaning.

``` r
unmatched_bakes_bakers_clean <- bakes_df_clean%>%
  anti_join(bakers_df, by = c("baker", "series"))
print(unmatched_bakes_bakers_clean)
```

    ## # A tibble: 0 × 5
    ## # ℹ 5 variables: series <dbl>, episode <dbl>, baker <chr>,
    ## #   signature_bake <chr>, show_stopper <chr>

``` r
unmatched_results_bakers_clean <- results_df_clean %>%
  anti_join(bakers_df, by = c("baker", "series"))
print(unmatched_results_bakers_clean)
```

    ## # A tibble: 0 × 5
    ## # ℹ 5 variables: series <dbl>, episode <dbl>, baker <chr>, technical <dbl>,
    ## #   result <chr>

``` r
unmatched_bakes_results_clean <- bakes_df_clean %>%
  anti_join(results_df_clean, by = c("baker", "series", "episode"))
print(unmatched_bakes_results_clean)
```

    ## # A tibble: 0 × 5
    ## # ℹ 5 variables: series <dbl>, episode <dbl>, baker <chr>,
    ## #   signature_bake <chr>, show_stopper <chr>

3.5 Combine the bakes and corresponding results.

I first combine the bakers_df and bake_df_clean using baker’s first name
and series they appear in so that the first name can be specific enough
to point to one person. Then, I focus on the combine of the results_df.
Since the bakes and results of same person have difference in each
episode, so I use three variables in linking the dataset.

``` r
final_data =
  bakers_df |>
  left_join(bakes_df_clean, by = c("baker", "series")) |>
  left_join(results_df_clean, by = c("baker", "series","episode"))
```

3.6 Reformat some details.

Since we have baker’s full name in baker.csv file, I am dropping baker’s
first name coloumn(‘baker’ variable) from bake.csv and results.csv.
Also,the columns are ordered in a way easy for users to look up. It
starts with the series and episode, then comes with the biography of the
baker and their signature bake, and finally is their technical score
given by the judge and result. I have re-coded the result into a
readable way according to the caption in results.csv file.

``` r
final_data_clean = 
  final_data |>
  select(series, episode, baker_name, baker_age, baker_occupation, hometown, signature_bake, show_stopper, technical, result) |>
  mutate(
    result = recode(result, "IN" = "stayed in", 'OUT' = 'Eliminated','STAR BAKER' = 'Star Baker', 'WINNER' = 'Series Winner', 'Runner-up' = 'Series Runner up', 'WD' = 'withdrew')
  )


dim(final_data_clean)
```

    ## [1] 573  10

``` r
str(final_data_clean)
```

    ## tibble [573 × 10] (S3: tbl_df/tbl/data.frame)
    ##  $ series          : num [1:573] 4 4 4 4 10 6 6 6 6 6 ...
    ##  $ episode         : num [1:573] 1 2 3 4 NA 1 2 3 4 5 ...
    ##  $ baker_name      : chr [1:573] "Ali Imdad" "Ali Imdad" "Ali Imdad" "Ali Imdad" ...
    ##  $ baker_age       : num [1:573] 25 25 25 25 28 37 37 37 37 37 ...
    ##  $ baker_occupation: chr [1:573] "Charity worker" "Charity worker" "Charity worker" "Charity worker" ...
    ##  $ hometown        : chr [1:573] "Saltley, Birmingham" "Saltley, Birmingham" "Saltley, Birmingham" "Saltley, Birmingham" ...
    ##  $ signature_bake  : chr [1:573] "Rose and Pistachio Cake" "Italian Grissini" "Coconut, Raspberry and Lemon Meringue Trifle" "Apple and Ginger Pie with a Pecan and Walnut Shortcrust Pastry" ...
    ##  $ show_stopper    : chr [1:573] "Chocolate, Raspberry and Passion Fruit Engagement Cake" "Sweet and Savoury Yin Yang Bread" "Vanilla Latte Mini CakesLime & Mint Shortbread Pops" "Orange, Cardamom and Date M'Hanncha" ...
    ##  $ technical       : num [1:573] 11 9 5 8 NA 2 6 4 9 8 ...
    ##  $ result          : chr [1:573] "stayed in" "stayed in" "stayed in" "Eliminated" ...

``` r
head(final_data)
```

    ## # A tibble: 6 × 11
    ##   baker_name       series baker_age baker_occupation  hometown     baker episode
    ##   <chr>             <dbl>     <dbl> <chr>             <chr>        <chr>   <dbl>
    ## 1 Ali Imdad             4        25 Charity worker    Saltley, Bi… Ali         1
    ## 2 Ali Imdad             4        25 Charity worker    Saltley, Bi… Ali         2
    ## 3 Ali Imdad             4        25 Charity worker    Saltley, Bi… Ali         3
    ## 4 Ali Imdad             4        25 Charity worker    Saltley, Bi… Ali         4
    ## 5 Alice Fevronia       10        28 Geography teacher Essex        Alice      NA
    ## 6 Alvin Magallanes      6        37 Nurse             Bracknell, … Alvin       1
    ## # ℹ 4 more variables: signature_bake <chr>, show_stopper <chr>,
    ## #   technical <dbl>, result <chr>

``` r
summary(final_data_clean)
```

    ##      series          episode        baker_name          baker_age    
    ##  Min.   : 1.000   Min.   : 1.000   Length:573         Min.   :17.00  
    ##  1st Qu.: 3.000   1st Qu.: 2.000   Class :character   1st Qu.:28.00  
    ##  Median : 5.000   Median : 4.000   Mode  :character   Median :33.00  
    ##  Mean   : 5.016   Mean   : 4.192                      Mean   :36.78  
    ##  3rd Qu.: 7.000   3rd Qu.: 6.000                      3rd Qu.:44.00  
    ##  Max.   :10.000   Max.   :10.000                      Max.   :71.00  
    ##                   NA's   :25                                         
    ##  baker_occupation     hometown         signature_bake     show_stopper      
    ##  Length:573         Length:573         Length:573         Length:573        
    ##  Class :character   Class :character   Class :character   Class :character  
    ##  Mode  :character   Mode  :character   Mode  :character   Mode  :character  
    ##                                                                             
    ##                                                                             
    ##                                                                             
    ##                                                                             
    ##    technical         result         
    ##  Min.   : 1.000   Length:573        
    ##  1st Qu.: 2.000   Class :character  
    ##  Median : 4.000   Mode  :character  
    ##  Mean   : 4.799                     
    ##  3rd Qu.: 7.000                     
    ##  Max.   :13.000                     
    ##  NA's   :32

``` r
write_csv(final_data_clean, "./data/final_bake_off_data.csv")
```

Discuss about the final_data_clean:

The dataset has 10 variables covering the exact series and episode show
that each baker was in, biography of the bakers, their bake and their
result. In total, we have 573 rated bakes and their bakers. All the
steps I used to clean and combine the data are written above. Please
refer to 3.1~3.6 for the exact steps.

3.7 Create a table of Star Bakers for Seasons 5-10

``` r
star_bakers = final_data_clean |>
  filter(series %in% 5:10 & (result == "Star Baker"|result == "Series Winner")) |>
  select(series, episode, baker_name, signature_bake, technical, result) |>
  arrange(series, episode)

print(star_bakers,n=Inf)
```

    ## # A tibble: 40 × 6
    ##    series episode baker_name           signature_bake           technical result
    ##     <dbl>   <dbl> <chr>                <chr>                        <dbl> <chr> 
    ##  1      5       1 Nancy Birtwhistle    Coffee and Hazelnut Swi…         1 Star …
    ##  2      5       2 Richard Burr         Rosemary Seeded Crackers         1 Star …
    ##  3      5       3 Luis Troyano         Opposites Attract Rolls          2 Star …
    ##  4      5       4 Richard Burr         Black Forest Chocolate …         5 Star …
    ##  5      5       5 Kate Henry           Rhubarb and Custard Tart         3 Star …
    ##  6      5       6 Chetna Makan         Orange Savarin with Cin…         2 Star …
    ##  7      5       7 Richard Burr         Minted Lamb Pasties              1 Star …
    ##  8      5       8 Richard Burr         Fruit Swedish Tea Ring           4 Star …
    ##  9      5       9 Richard Burr         Rose and Pistachio Bakl…         2 Star …
    ## 10      5      10 Nancy Birtwhistle    Apple and Lemon KitesRa…         1 Serie…
    ## 11      6       1 Marie Campbell       Zingy Citrus Madeira Ca…         3 Star …
    ## 12      6       2 Ian Cumming          Orange, Rosemary and Al…         3 Star …
    ## 13      6       3 Ian Cumming          Wild Garlic Pesto Soda …         1 Star …
    ## 14      6       4 Ian Cumming          Pomegranate Two Ways Cr…         4 Star …
    ## 15      6       5 Nadiya Hussain       Naked Blueberry and Car…         1 Star …
    ## 16      6       6 Mat Riley            Piña Colada Frangipane …         1 Star …
    ## 17      6       7 Tamal Ray            Middle Eastern Game Pie          3 Star …
    ## 18      6       8 Nadiya Hussain       Rose Pistachio and Moch…         1 Star …
    ## 19      6       9 Nadiya Hussain       Peanut Salted Caramel a…         4 Star …
    ## 20      6      10 Nadiya Hussain       Cardamom and Almond Bun…         1 Serie…
    ## 21      7       1 Jane Beedle          Lemon and Poppy Seed Dr…         7 Star …
    ## 22      7       2 Candice Brown        Salted Caramel, Chocola…         8 Star …
    ## 23      7       3 Tom Gilliford        Chocolate Orange and Ch…         4 Star …
    ## 24      7       4 Benjamina Ebuehi     Red Onion Chutney, Brie…         1 Star …
    ## 25      7       5 Candice Brown        Danish Pastry Croque Mo…         2 Star …
    ## 26      7       6 Tom Gilliford        Blood Orange Halloween …         1 Star …
    ## 27      7       7 Andrew Smyth         Tropical Holiday Roulade         1 Star …
    ## 28      7       8 Candice Brown        Cheesy Cheeky Fish Pies          1 Star …
    ## 29      7       9 Andrew Smyth         Cheesy Elephant Ears an…         2 Star …
    ## 30      7      10 Candice Brown        Queen Victoria's Mango …         2 Serie…
    ## 31      8       1 Steven Carter-Bailey Bonfire Night Cake               6 Star …
    ## 32      8       2 Steven Carter-Bailey Amarpressi Biscuits              6 Star …
    ## 33      8       3 Julia Chernogorova   Earl Grey Dried Fruit T…         2 Star …
    ## 34      8       4 Kate Lyon            Salted Bay Caramel Mill…         6 Star …
    ## 35      8       5 Sophie Faldo         Ginger, Fig and Honey S…         1 Star …
    ## 36      8       6 Liam Charles         'Standard FC' Decorativ…         4 Star …
    ## 37      8       7 Steven Carter-Bailey Italian Style Cannoli            1 Star …
    ## 38      8       8 Stacey Hart          Camembert & Onion and A…         3 Star …
    ## 39      8       9 Sophie Faldo         Strawberry & Rhubarb an…         1 Star …
    ## 40      8      10 Sophie Faldo         Spelt Boules, Mushroom …         2 Serie…

Conclusion: - the dataset only supports series 5 to 8(since series 9 and
10 dosen’t have the exact result for each baker) -We assume that there
is a strong relationship between the number of times each baker gets a
STAR BAKER and getting WINNER OF THE SEASON. That is to say, the more
‘star bakers’ a baker gets, the more likely he or she is to be the
winner of the season. Therefore, we can comment the results on this
base. For example, if someone got never/less times of star bakers win
the season, we will call it a surprise. - In season5, Nancy
Birtwhistle’s winning is a surprise considering Richard Burr had won 4
‘star bakers’ over the season while Nancy only got one. - In season6 and
season 7 , Nadiya Hussain and Candice Brown are absolutely predictable
winners.They had won ‘star bakers’ throughout the season 3 times and
twice, respectively. The number of times winning ‘star bakers’ are way
over others. - In season 8, Sophie Faldo’s winning of the series is
quite a surprice since she had only won one ‘Star Baker’ during the
whole season.

3.8 Import, clean, and analyze viewers.csv

``` r
viewers_df =
  read_csv("./data/gbb_datasets/viewers.csv") |>
  janitor::clean_names()
```

``` r
# Show first 10 rows
head(viewers_df,10)
```

    ## # A tibble: 10 × 11
    ##    episode series_1 series_2 series_3 series_4 series_5 series_6 series_7
    ##      <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>
    ##  1       1     2.24     3.1      3.85     6.6      8.51     11.6     13.6
    ##  2       2     3        3.53     4.6      6.65     8.79     11.6     13.4
    ##  3       3     3        3.82     4.53     7.17     9.28     12.0     13.0
    ##  4       4     2.6      3.6      4.71     6.82    10.2      12.4     13.3
    ##  5       5     3.03     3.83     4.61     6.95     9.95     12.4     13.1
    ##  6       6     2.75     4.25     4.82     7.32    10.1      12       13.1
    ##  7       7    NA        4.42     5.1      7.76    10.3      12.4     13.4
    ##  8       8    NA        5.06     5.35     7.41     9.02     11.1     13.3
    ##  9       9    NA       NA        5.7      7.41    10.7      12.6     13.4
    ## 10      10    NA       NA        6.74     9.45    13.5      15.0     15.9
    ## # ℹ 3 more variables: series_8 <dbl>, series_9 <dbl>, series_10 <dbl>

``` r
# Calculate average viewership for Seasons 1 and 5
avg_viewership_season_1 = viewers_df |>
  summarise(avg_viewership = mean(series_1, na.rm = TRUE))
avg_viewership_season_5 = viewers_df |>
  summarise(avg_viewership = mean(series_5, na.rm = TRUE))

cat("the average viewership in Season 1:",avg_viewership_season_1$avg_viewership,"the average viewership in Season 5:",avg_viewership_season_5$avg_viewership,"")
```

    ## the average viewership in Season 1: 2.77 the average viewership in Season 5: 10.0393
